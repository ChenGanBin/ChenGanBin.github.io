---
title: 决策树
tags:
categories:
mathjax:
  enable: true
---

决策树

<!-- more -->

决策树

优点：计算复杂度不高，输出结果义域理解，对中间值的缺失不敏感，可以处理不相关特征数据
缺点：可能会产生过度匹配问题
适用数据类型：数值型和标称型

决策树的一般流程

1. 收集数据：可以使用任何方法
2. 准备数据：树构造算法只适用于标称型数据，因此数值型数据必须离散化
3. 分析数据：可以使用任何方法，构造树完成之后，我们应该检查图形是否符合预期
4. 训练算法：构造树的数据结构
5. 测试算法：使用经验树计算错误率
6. 使用算法：此步骤可以适用于任何监督学习算法，而使用决策树可以更好地理解数据的内在含义

划分数据集的原则：将无序的数据变得更加有序

组织杂乱无章数据的一种方法就是使用*信息论*度量信息，在划分数据集之前之后信息发生的变化成为信息增益，获得信息增益最高的特征就是最好的选择

# 信息增益

集合信息的度量方式称为香农熵或者简称为熵

熵定义为信息的期望值

如果带分类的事务可能划分在多个分类之中，则符号的信息定义为$E=mc^2$
其中是选择该分类的概率
